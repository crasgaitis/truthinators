{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Things to track:\n",
    "- Pitch\n",
    "- Content of speech (\"um\", \"uhh\", laughing)\n",
    "- Response time (hesitation)\n",
    "- How specific is the answer\n",
    "\n",
    "Consider normalizing speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press 'q' to stop.\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import keyboard\n",
    "\n",
    "# Initialize pyaudio\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Define stream parameters\n",
    "CHANNELS = 1\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "\n",
    "# Open stream\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording... Press 'q' to stop.\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "# Record audio until 'q' is pressed\n",
    "while not keyboard.is_pressed('q'):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded data to a file\n",
    "wf = wave.open(\"output.wav\", 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Google's Cloud Speech-To-Text\n",
    "https://cloud.google.com/speech-to-text/docs/transcribe-streaming-audio#speech-streaming-recognize-python\n",
    "\n",
    "This transcribes streaming audio to text.\n",
    "\n",
    "To install the library:\n",
    "pip install --upgrade google-cloud-speech\n",
    "\n",
    "Download the gcloud CLI: https://cloud.google.com/sdk/docs/install.\n",
    "\n",
    "Configure the development environment. \n",
    "<img src=\"attachment:image.png\" width=\"300\"/>\n",
    "\n",
    "For some reason you have to go here to accept terms of service with gcloud, before doing \"gcloud init\" command\n",
    "https://console.cloud.google.com/terms/universal?pli=\n",
    "\n",
    "You have to request access to use this, as it looks like 1 specific person will \"own\" the project. People can be added directly to the project.\n",
    "\n",
    "Info:\n",
    "Project name: truthinators\n",
    "Project number: 399310020607\n",
    "Project ID: truthinators\n",
    "\n",
    "You have to enable the Speech to Text API for the specific project + add billing :(\n",
    "\n",
    "API Request limits: \n",
    "https://cloud.google.com/speech-to-text/quotas\n",
    "For our purposes, we should not be going over the API limitations (it's like... 480 hours of audio per day, 900 requests per 60 seconds).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: how old is the Brooklyn Bridge\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports the Google Cloud client library\n",
    "\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "\n",
    "\n",
    "def run_quickstart() -> speech.RecognizeResponse:\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    gcs_uri = \"gs://cloud-samples-data/speech/brooklyn_bridge.raw\"\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "run_quickstart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      " this is a test file\n",
      " can I wait can I actively read this\n",
      " exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import queue\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "import pyaudio\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "\n",
    "\n",
    "class MicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self: object, rate: int = RATE, chunk: int = CHUNK) -> None:\n",
    "        \"\"\"The audio -- and generator -- is guaranteed to be on the main thread.\"\"\"\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self: object) -> object:\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(\n",
    "        self: object,\n",
    "        type: object,\n",
    "        value: object,\n",
    "        traceback: object,\n",
    "    ) -> None:\n",
    "        \"\"\"Closes the stream, regardless of whether the connection was lost or not.\"\"\"\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(\n",
    "        self: object,\n",
    "        in_data: object,\n",
    "        frame_count: int,\n",
    "        time_info: object,\n",
    "        status_flags: object,\n",
    "    ) -> object:\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\n",
    "\n",
    "        Args:\n",
    "            in_data: The audio data as a bytes object\n",
    "            frame_count: The number of frames captured\n",
    "            time_info: The time information\n",
    "            status_flags: The status flags\n",
    "\n",
    "        Returns:\n",
    "            The audio data as a bytes object\n",
    "        \"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self: object) -> object:\n",
    "        \"\"\"Generates audio chunks from the stream of audio data in chunks.\n",
    "\n",
    "        Args:\n",
    "            self: The MicrophoneStream object\n",
    "\n",
    "        Returns:\n",
    "            A generator that outputs audio chunks.\n",
    "        \"\"\"\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)\n",
    "\n",
    "\n",
    "def listen_print_save_loop(responses: object, name: str) -> str:\n",
    "    \"\"\"Iterates through server responses and prints them.\n",
    "\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "\n",
    "    Each response may contain multiple results, and each result may contain\n",
    "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
    "    print only the transcription for the top alternative of the top result.\n",
    "\n",
    "    In this case, responses are provided for interim results as well. If the\n",
    "    response is an interim one, print a line feed at the end of it, to allow\n",
    "    the next result to overwrite it, until the response is a final one. For the\n",
    "    final one, print a newline to preserve the finalized transcription.\n",
    "    \n",
    "    Transcript is also added to \"transcription.txt\"\n",
    "\n",
    "    Args:\n",
    "        responses: List of server responses\n",
    "\n",
    "    Returns:\n",
    "        The transcribed text.\n",
    "    \"\"\"\n",
    "    num_chars_printed = 0\n",
    "    final_transcript = \"\"\n",
    "\n",
    "    with open(f'{name}.txt', \"w\") as file:\n",
    "        for response in responses:\n",
    "            if not response.results:\n",
    "                continue\n",
    "\n",
    "            # Process the first result in the response\n",
    "            result = response.results[0]\n",
    "            if not result.alternatives:\n",
    "                continue\n",
    "\n",
    "            # Extract the top alternative transcript\n",
    "            transcript = result.alternatives[0].transcript\n",
    "\n",
    "            # Handle interim results with overwrite\n",
    "            overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "\n",
    "            if not result.is_final:\n",
    "                sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "                sys.stdout.flush()\n",
    "                num_chars_printed = len(transcript)\n",
    "            else:\n",
    "                # Final result: print and save to file\n",
    "                print(transcript + overwrite_chars)\n",
    "                file.write(transcript + overwrite_chars + \"\\n\")\n",
    "\n",
    "                # Check for exit keywords\n",
    "                if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
    "                    print(\"Exiting...\")\n",
    "                    break\n",
    "\n",
    "                # Reset character count and append to final transcript\n",
    "                num_chars_printed = 0\n",
    "                final_transcript += transcript + \" \"\n",
    "\n",
    "    return final_transcript.strip()\n",
    "\n",
    "def save_audio_to_file(responses: object, name: str) -> None:\n",
    "    \"\"\"Saves audio data to an output file.\n",
    "\n",
    "    The responses passed is a generator that will block until a response\n",
    "    is provided by the server.\n",
    "\n",
    "    Args:\n",
    "        responses: List of server responses\n",
    "    \"\"\"\n",
    "    with open((f'{name}.raw'), \"wb\") as f:\n",
    "        for response in responses:\n",
    "            if not response.results:\n",
    "                continue\n",
    "            f.write(response.results[0].audio_content)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Transcribe speech from audio file.\"\"\"\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    language_code = \"en-US\"  # a BCP-47 language tag\n",
    "    \n",
    "    participant_name = input()\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code,\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content)\n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        # Now, put the transcription responses to use.\n",
    "        listen_print_save_loop(responses, participant_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
