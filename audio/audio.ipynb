{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Things to track:\n",
    "- Pitch\n",
    "- Content of speech (\"um\", \"uhh\", laughing)\n",
    "- Response time (hesitation)\n",
    "- How specific is the answer\n",
    "\n",
    "Consider normalizing speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press 'q' to stop.\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import keyboard\n",
    "\n",
    "# Initialize pyaudio\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Define stream parameters\n",
    "CHANNELS = 1\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "\n",
    "# Open stream\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording... Press 'q' to stop.\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "# Record audio until 'q' is pressed\n",
    "while not keyboard.is_pressed('q'):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded data to a file\n",
    "wf = wave.open(\"output.wav\", 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Google's Cloud Speech-To-Text\n",
    "https://cloud.google.com/speech-to-text/docs/transcribe-streaming-audio#speech-streaming-recognize-python\n",
    "\n",
    "This transcribes streaming audio to text.\n",
    "\n",
    "To install the library:\n",
    "pip install --upgrade google-cloud-speech\n",
    "\n",
    "Download the gcloud CLI: https://cloud.google.com/sdk/docs/install.\n",
    "\n",
    "Configure the development environment. \n",
    "<img src=\"attachment:image.png\" width=\"300\"/>\n",
    "\n",
    "For some reason you have to go here to accept terms of service with gcloud, before doing \"gcloud init\" command\n",
    "https://console.cloud.google.com/terms/universal?pli=\n",
    "\n",
    "You have to request access to use this, as it looks like 1 specific person will \"own\" the project. People can be added directly to the project.\n",
    "\n",
    "Info:\n",
    "Project name: truthinators\n",
    "Project number: 399310020607\n",
    "Project ID: truthinators\n",
    "\n",
    "You have to enable the Speech to Text API for the specific project + add billing :(\n",
    "\n",
    "API Request limits: \n",
    "https://cloud.google.com/speech-to-text/quotas\n",
    "For our purposes, we should not be going over the API limitations (it's like... 480 hours of audio per day, 900 requests per 60 seconds).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: Microsoft Sound Mapper - Input\n",
      "Index 1: Microphone Array (IntelÂ® Smart \n",
      "Index 2: Headset (IntelÂ® Smart Sound Tec\n",
      "Index 6: Primary Sound Capture Driver\n",
      "Index 7: Microphone Array (IntelÂ® Smart Sound Technology for Digital Microphones)\n",
      "Index 8: Headset (IntelÂ® Smart Sound Technology for BluetoothÂ® Audio)\n",
      "Index 14: Headset (IntelÂ® Smart Sound Technology for BluetoothÂ® Audio)\n",
      "Index 15: Microphone Array (IntelÂ® Smart Sound Technology for Digital Microphones)\n",
      "Index 18: Input (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Jabra Evolve2 75))\n",
      "Index 20: Headset 1 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Jabra Evolve2 75))\n",
      "Index 21: Headset 2 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Jabra Evolve2 75))\n",
      "Index 24: Input (@System32\\drivers\\btha2dp.sys,#1;%1%0\n",
      ";(Jabra Evolve2 75))\n",
      "Index 26: Microphone (Mic in at front panel (black))\n",
      "Index 27: Stereo Mix (Realtek HD Audio Stereo input)\n",
      "Index 30: PC Speaker (Realtek HD Audio output with SST)\n",
      "Index 33: PC Speaker (Realtek HD Audio 2nd output with SST)\n",
      "Index 35: Microphone Array 1 ()\n",
      "Index 36: Microphone Array 2 ()\n",
      "Index 37: Microphone Array 3 ()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "    info = p.get_device_info_by_index(i)\n",
    "    if info[\"maxInputChannels\"] > 0:\n",
    "        print(f\"Index {i}: {info['name']}\")\n",
    "\n",
    "p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter participant name: \n",
      "Recording... Say 'exit' or 'quit' OR press 'q' to stop.\n",
      "Recording from Headset (IntelÂ® Smart Sound Tec...\n",
      "你好吗\n",
      "我叫王晓阳我的朋友\n",
      "\n",
      "Stopped by keyboard ('q' pressed)\n",
      "\n",
      "Audio saved to test_audio.wav\n",
      "Transcript saved to test_transcript.txt\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import re\n",
    "import sys\n",
    "import wave\n",
    "import threading\n",
    "from google.cloud import speech\n",
    "import pyaudio\n",
    "import keyboard\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "INPUT_DEVICE_INDEX = 2\n",
    "LANGUAGE_CODE = \"en-US\"\n",
    "'''\n",
    "Common language codes:\n",
    "English: en-US\n",
    "French: fr-FR\n",
    "Spanish: es-ES\n",
    "German: de-DE\n",
    "Chinese (simplified): cmn-Hans-CN\n",
    "Japanese: ja-JP\n",
    "Italian: it-IT\n",
    "\n",
    "Full list: https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages\n",
    "'''\n",
    "\n",
    "class MicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self, rate=RATE, chunk=CHUNK):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "        self.audio_frames = []  # Store audio frames for saving\n",
    "        self.should_stop = False  # Flag for keyboard interrupt\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=FORMAT,\n",
    "            channels=CHANNELS,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            stream_callback=self._fill_buffer,\n",
    "            input_device_index=INPUT_DEVICE_INDEX\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "        \n",
    "    def _getMicrophone(self):\n",
    "        info = self._audio_interface.get_device_info_by_index(INPUT_DEVICE_INDEX)\n",
    "        return info[\"name\"]\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        self.audio_frames.append(in_data)  # Save audio data for WAV file\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        \"\"\"Generates audio chunks from the stream of audio data.\"\"\"\n",
    "        while not self.closed and not self.should_stop:\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)\n",
    "\n",
    "    def save_audio(self, filename):\n",
    "        \"\"\"Save the recorded audio to a WAV file.\"\"\"\n",
    "        wf = wave.open(filename, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(self._audio_interface.get_sample_size(FORMAT))\n",
    "        wf.setframerate(self._rate)\n",
    "        wf.writeframes(b''.join(self.audio_frames))\n",
    "        wf.close()\n",
    "        print(f\"\\nAudio saved to {filename}\")\n",
    "\n",
    "def check_for_quit(stream):\n",
    "    \"\"\"Monitor for 'q' key press.\"\"\"\n",
    "    keyboard.wait('q')\n",
    "    stream.should_stop = True\n",
    "    print(\"\\nStopped by keyboard ('q' pressed)\")\n",
    "\n",
    "def listen_print_save_loop(responses, stream, name):\n",
    "    \"\"\"Iterates through server responses and prints them while recording audio.\"\"\"\n",
    "    num_chars_printed = 0\n",
    "    final_transcript = \"\"\n",
    "\n",
    "    with open(f'{name}_transcript.txt', \"w\", encoding=\"utf-8\") as file:\n",
    "        for response in responses:\n",
    "            if stream.should_stop:\n",
    "                break\n",
    "\n",
    "            if not response.results:\n",
    "                continue\n",
    "\n",
    "            result = response.results[0]\n",
    "            if not result.alternatives:\n",
    "                continue\n",
    "\n",
    "            transcript = result.alternatives[0].transcript\n",
    "            overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "\n",
    "            if not result.is_final:\n",
    "                sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "                sys.stdout.flush()\n",
    "                num_chars_printed = len(transcript)\n",
    "            else:\n",
    "                print(transcript + overwrite_chars)\n",
    "                file.write(transcript + overwrite_chars + \"\\n\")\n",
    "\n",
    "                if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
    "                    print(\"\\nStopped by voice command ('exit' or 'quit' detected)\")\n",
    "                    stream.should_stop = True\n",
    "                    break\n",
    "\n",
    "                num_chars_printed = 0\n",
    "                final_transcript += transcript + \" \"\n",
    "\n",
    "    # Save audio file before exiting\n",
    "    stream.save_audio(f\"{name}_audio.wav\")\n",
    "    print(f\"Transcript saved to {name}_transcript.txt\")\n",
    "    return final_transcript.strip()\n",
    "\n",
    "def main():    \n",
    "    print(\"Enter participant name: \")\n",
    "    participant_name = input().strip()\n",
    "    \n",
    "    print(\"Recording... Say 'exit' or 'quit' OR press 'q' to stop.\")\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=LANGUAGE_CODE,\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        print(f\"Recording from {stream._getMicrophone()}...\")\n",
    "        # Start keyboard monitoring in a separate thread\n",
    "        keyboard_thread = threading.Thread(target=check_for_quit, args=(stream,))\n",
    "        keyboard_thread.daemon = True\n",
    "        keyboard_thread.start()\n",
    "\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content)\n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            responses = client.streaming_recognize(streaming_config, requests)\n",
    "            listen_print_save_loop(responses, stream, participant_name)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred: {e}\")\n",
    "            stream.save_audio(f\"{participant_name}_audio.wav\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
