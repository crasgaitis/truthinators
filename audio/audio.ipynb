{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Things to track:\n",
    "- Pitch\n",
    "- Content of speech (\"um\", \"uhh\", laughing)\n",
    "- Response time (hesitation)\n",
    "- How specific is the answer\n",
    "\n",
    "Consider normalizing speech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press 'q' to stop.\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import keyboard\n",
    "\n",
    "# Initialize pyaudio\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Define stream parameters\n",
    "CHANNELS = 1\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "\n",
    "# Open stream\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording... Press 'q' to stop.\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "# Record audio until 'q' is pressed\n",
    "while not keyboard.is_pressed('q'):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded data to a file\n",
    "wf = wave.open(\"output.wav\", 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Google's Cloud Speech-To-Text\n",
    "https://cloud.google.com/speech-to-text/docs/transcribe-streaming-audio#speech-streaming-recognize-python\n",
    "\n",
    "This transcribes streaming audio to text.\n",
    "\n",
    "To install the library:\n",
    "pip install --upgrade google-cloud-speech\n",
    "\n",
    "Download the gcloud CLI: https://cloud.google.com/sdk/docs/install.\n",
    "\n",
    "Configure the development environment. \n",
    "<img src=\"attachment:image.png\" width=\"300\"/>\n",
    "\n",
    "For some reason you have to go here to accept terms of service with gcloud, before doing \"gcloud init\" command\n",
    "https://console.cloud.google.com/terms/universal?pli=\n",
    "\n",
    "You have to request access to use this, as it looks like 1 specific person will \"own\" the project. People can be added directly to the project.\n",
    "\n",
    "Info:\n",
    "Project name: truthinators\n",
    "Project number: 399310020607\n",
    "Project ID: truthinators\n",
    "\n",
    "You have to enable the Speech to Text API for the specific project + add billing :(\n",
    "\n",
    "API Request limits: \n",
    "https://cloud.google.com/speech-to-text/quotas\n",
    "For our purposes, we should not be going over the API limitations (it's like... 480 hours of audio per day, 900 requests per 60 seconds).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: how old is the Brooklyn Bridge\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports the Google Cloud client library\n",
    "\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "\n",
    "\n",
    "def run_quickstart() -> speech.RecognizeResponse:\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    gcs_uri = \"gs://cloud-samples-data/speech/brooklyn_bridge.raw\"\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "run_quickstart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter participant name: \n",
      "Recording... Say 'exit' or 'quit' OR press 'q' to stop.\n",
      "can you hear me\n",
      " this is the test\n",
      " this is a test\n",
      " this is a lie\n",
      " this is a truth\n",
      "\n",
      "Stopped by keyboard ('q' pressed)\n",
      "\n",
      "Audio saved to test subject_audio.wav\n",
      "Transcript saved to test subject_transcript.txt\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import re\n",
    "import sys\n",
    "import wave\n",
    "import threading\n",
    "from google.cloud import speech\n",
    "import pyaudio\n",
    "import keyboard\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "\n",
    "class MicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self, rate=RATE, chunk=CHUNK):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "        self.audio_frames = []  # Store audio frames for saving\n",
    "        self.should_stop = False  # Flag for keyboard interrupt\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=FORMAT,\n",
    "            channels=CHANNELS,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        self.audio_frames.append(in_data)  # Save audio data for WAV file\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        \"\"\"Generates audio chunks from the stream of audio data.\"\"\"\n",
    "        while not self.closed and not self.should_stop:\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)\n",
    "\n",
    "    def save_audio(self, filename):\n",
    "        \"\"\"Save the recorded audio to a WAV file.\"\"\"\n",
    "        wf = wave.open(filename, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(self._audio_interface.get_sample_size(FORMAT))\n",
    "        wf.setframerate(self._rate)\n",
    "        wf.writeframes(b''.join(self.audio_frames))\n",
    "        wf.close()\n",
    "        print(f\"\\nAudio saved to {filename}\")\n",
    "\n",
    "def check_for_quit(stream):\n",
    "    \"\"\"Monitor for 'q' key press.\"\"\"\n",
    "    keyboard.wait('q')\n",
    "    stream.should_stop = True\n",
    "    print(\"\\nStopped by keyboard ('q' pressed)\")\n",
    "\n",
    "def listen_print_save_loop(responses, stream, name):\n",
    "    \"\"\"Iterates through server responses and prints them while recording audio.\"\"\"\n",
    "    num_chars_printed = 0\n",
    "    final_transcript = \"\"\n",
    "\n",
    "    with open(f'{name}_transcript.txt', \"w\") as file:\n",
    "        for response in responses:\n",
    "            if stream.should_stop:\n",
    "                break\n",
    "\n",
    "            if not response.results:\n",
    "                continue\n",
    "\n",
    "            result = response.results[0]\n",
    "            if not result.alternatives:\n",
    "                continue\n",
    "\n",
    "            transcript = result.alternatives[0].transcript\n",
    "            overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "\n",
    "            if not result.is_final:\n",
    "                sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "                sys.stdout.flush()\n",
    "                num_chars_printed = len(transcript)\n",
    "            else:\n",
    "                print(transcript + overwrite_chars)\n",
    "                file.write(transcript + overwrite_chars + \"\\n\")\n",
    "\n",
    "                if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
    "                    print(\"\\nStopped by voice command ('exit' or 'quit' detected)\")\n",
    "                    stream.should_stop = True\n",
    "                    break\n",
    "\n",
    "                num_chars_printed = 0\n",
    "                final_transcript += transcript + \" \"\n",
    "\n",
    "    # Save audio file before exiting\n",
    "    stream.save_audio(f\"{name}_audio.wav\")\n",
    "    print(f\"Transcript saved to {name}_transcript.txt\")\n",
    "    return final_transcript.strip()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to handle both transcription and audio recording.\"\"\"\n",
    "    language_code = \"en-US\"\n",
    "    \n",
    "    print(\"Enter participant name: \")\n",
    "    participant_name = input().strip()\n",
    "    \n",
    "    print(\"Recording... Say 'exit' or 'quit' OR press 'q' to stop.\")\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code,\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        # Start keyboard monitoring in a separate thread\n",
    "        keyboard_thread = threading.Thread(target=check_for_quit, args=(stream,))\n",
    "        keyboard_thread.daemon = True\n",
    "        keyboard_thread.start()\n",
    "\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content)\n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            responses = client.streaming_recognize(streaming_config, requests)\n",
    "            listen_print_save_loop(responses, stream, participant_name)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred: {e}\")\n",
    "            stream.save_audio(f\"{participant_name}_audio.wav\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
